name: harvest-train
on:
  schedule: [{ cron: "20 3 * * *" }]   # 03:20 UTC ≈ 05:20 DK
  workflow_dispatch:
jobs:
  run:
    runs-on: ubuntu-latest
    env:
      POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
      APIFOOTBALL_KEY: ${{ secrets.APIFOOTBALL_KEY }}
      TZ: Europe/Copenhagen
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }
      - run: |
          python -m pip install --upgrade pip
          python -m pip install "sqlalchemy>=2" "psycopg[binary]" pandas numpy pyarrow joblib scikit-learn requests
      - name: Build features — show CLI
        run: |
          python scripts/build_features.py --help || true

      - name: Build features (harvest window)
        env:
          APIFOOTBALL_KEY: ${{ secrets.APIFOOTBALL_KEY }}
        run: |
          set -e
          python scripts/build_features.py --harvest-postmatch --days-back 2 --days-fwd 0

      - name: Build features (merge + write train_set)
        env:
          POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
        run: |
          set -e
          python scripts/build_features.py --merge-train-stats-from-db --write-train-set
          python - <<'PY'
          import os, pandas as pd
          p = 'data/features/train_set.parquet'
          if not os.path.exists(p):
              raise SystemExit(f"❌ {p} missing after build")
          df = pd.read_parquet(p)
          print('✅ train_set.parquet rows:', len(df), 'cols:', len(df.columns))
          PY

      - name: Fetch fixtures odds → CSV + snapshots
        env:
          APIFOOTBALL_KEY: ${{ secrets.APIFOOTBALL_KEY }}
        run: |
          python scripts/fetch_apifootball_odds.py --days 14 --include-ou25 --include-ah --write-parquet

      - name: Train models (1x2 / ou25 / ahm05)
        env:
          POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
        run: |
          python scripts/train_models.py
